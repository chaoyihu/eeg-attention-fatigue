{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import io\n",
    "from sklearn.utils import shuffle\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "def filt_coef(order, cutoff, filt_type, sampleRate):\n",
    "    Nq = sampleRate//2\n",
    "    Wn = cutoff / Nq\n",
    "    b, a = scipy.signal.butter(order, Wn, filt_type)\n",
    "    return b, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = r\"..\\1230\\data\\data3\\raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all edf files under this directory\n",
    "\n",
    "ls = os.listdir(home)\n",
    "newls = []\n",
    "for fname in ls:\n",
    "    if fname.endswith('.edf'):\n",
    "        newls.append(fname)\n",
    "newls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Or uncomment this block to customize the files you want to include in your dataset\n",
    "\n",
    "# newls = [\n",
    "#     '0201_11.edf',\n",
    "#     '0201_12.edf',\n",
    "#     '0201_13.edf'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 1000 # length of the input array needed\n",
    "sampleRate = 1000 # sample rate of raw data\n",
    "\n",
    "datacuts = []\n",
    "labels = []\n",
    "threshold = 100 # This is to reduce noise in data: cut all the data points beyond [-threshold, threshold]\n",
    "\n",
    "for fname in newls:\n",
    "    fpath = os.path.join(r\"..\\data\\data2\\raw\", fname)\n",
    "\n",
    "    r = io.read_raw_edf(fpath)\n",
    "    r.drop_channels(['ECG', 'VEOG', 'HEOG'])\n",
    "    unfilter_datacut = r.load_data()[['Fp1','Fp2']][0]\n",
    "    unfilter_datacut = np.array(unfilter_datacut)\n",
    "    \n",
    "    # filter the data\n",
    "    b, a = filt_coef(2, 30, 'lowpass', sampleRate)\n",
    "    d, c = filt_coef(5, 1, 'highpass', sampleRate)    \n",
    "    unfilter_datacut[0] = scipy.signal.filtfilt(b, a, unfilter_datacut[0])\n",
    "    unfilter_datacut[1] = scipy.signal.filtfilt(b, a, unfilter_datacut[1])\n",
    "    unfilter_datacut[0] = scipy.signal.filtfilt(d, c, unfilter_datacut[0])\n",
    "    unfilter_datacut[1] = scipy.signal.filtfilt(d, c, unfilter_datacut[1])\n",
    "    \n",
    "    \n",
    "    # cut all the data points beyond [-threshold, threshold]\n",
    "    unfilter_datacut = np.transpose(unfilter_datacut)\n",
    "    print(unfilter_datacut.shape)\n",
    "    datacut = []\n",
    "    for i,j in unfilter_datacut:\n",
    "        if abs(i) <= threshold and abs(j) <= threshold:\n",
    "            datacut.append([i,j])\n",
    "    datacut = np.transpose(np.array(datacut))\n",
    "    print(\"datacut:\", datacut.shape)\n",
    "\n",
    "    \n",
    "    # normalise to [0, 1]\n",
    "    datacut[0] = datacut[0] - min(datacut[0])\n",
    "    datacut[1] = datacut[1] - min(datacut[1])\n",
    "    scale = 2 * threshold\n",
    "    datacut[0] = datacut[0] / scale\n",
    "    datacut[1] = datacut[1] / scale\n",
    "\n",
    "    # resample the array to 500Hz\n",
    "    datacut = datacut[:, ::2]\n",
    "\n",
    "    \n",
    "    # cut the long array to short ones, length: 2s.\n",
    "    l = datacut.shape[1] # data points\n",
    "    n = int(l / window_length) # number of cuts\n",
    "    # Triple classification: L/M/H\n",
    "    label = int(fname.split(\"_\")[0][1]) - 1.0 # 0,1,2\n",
    "    for start in [i * window_length for i in list(range(n))]:\n",
    "#         label = int(fname.split('_')[-2][1]) - 1\n",
    "        arr = datacut[:, start: start + window_length]\n",
    "        datacuts.append(arr)\n",
    "        labels.append(label)\n",
    "\n",
    "    print(len(datacuts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "datacuts, labels = shuffle(datacuts, labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacuts = np.array(datacuts)\n",
    "datacuts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of samples in each class to make sure it's balanced\n",
    "from collections import Counter\n",
    "d = Counter(labels)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(labels)):\n",
    "    plt.plot(datacuts[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your dataset, remember to change the file name!\n",
    "\n",
    "dataset = [datacuts, labels]\n",
    "\n",
    "save_file = \"..\\\\data\\\\data3_attention\\\\fatigue_sub1101_low_fp1fp2_2s_resampled500Hz.pkl\"\n",
    "with open(save_file, 'wb') as handle:\n",
    "            # pickle.dump(dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump(dataset, handle, protocol=2)\n",
    "    print(\"saved:\", save_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
